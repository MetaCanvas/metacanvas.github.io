<!DOCTYPE html>
<html>

<head>
	<meta charset="utf-8">
	<meta name="description" content="Exploring MLLM-Diffusion Information Transfer with MetaCanvas">
	<meta name="keywords" 
		content="image generation,video generation,unified models,MLLM,diffusion,genai,transfer">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>MetaCanvas</title>

	<script>
		window.dataLayer = window.dataLayer || [];

		function gtag() {
			dataLayer.push(arguments);
		}

		gtag('js', new Date());

		gtag('config', 'G-PYVRSFMDRL');
	</script>

	<link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

	<link rel="stylesheet" href="./static/css/bulma.min.css">
	<link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
	<link rel="stylesheet" href="./static/css/bulma-slider.min.css">
	<link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
	<link rel="stylesheet" href="./static/css/index.css">
	<!-- <link rel="icon" href="./static/images/favicon.svg"> -->

	<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
	<script defer src="./static/js/fontawesome.all.min.js"></script>
	<script src="./static/js/bulma-carousel.min.js"></script>
	<script src="./static/js/bulma-slider.min.js"></script>
	<script src="./static/js/index.js"></script>
</head>

<body>
	<section class="hero">
		<div class="hero-body">
			<div class="container is-max-desktop">
				<div class="columns is-centered">
					<div class="column has-text-centered">
						<h1 class="title is-1 publication-title">
							<!-- <span style="color: rgb(237, 178, 13);">C</span><span style="color: rgb(112, 48, 160);">T</span><span style="color: rgb(0, 176, 240);">R</span><span style="color: rgb(215, 49, 136);">L</span>-Adapter -->
							Exploring MLLM-Diffusion Information Transfer with <br> 
							<span style="color: rgb(112, 48, 160); font-size: 1em;">MetaCanvas</span>
						</h1>
						<div class="is-size-5 publication-authors">
							<span class="author-block">
							  <a href="https://hl-hanlin.github.io/" target="_blank">
								Han Lin<sup>1,2,*</sup>
							  </a>
							</span>,&nbsp;
						  
							<span class="author-block">
							  <a href="https://xichenpan.com/" target="_blank">
								Xichen Pan<sup>1,3</sup>
							  </a>
							</span>,&nbsp;
						  
							<span class="author-block">
							  <a href="https://ziqihuangg.github.io/" target="_blank">
								Ziqi Huang<sup>1,4,*</sup>
							  </a>
							</span>,&nbsp;
						  
							<span class="author-block">
							  <a href="https://sekunde.github.io/" target="_blank">
								Ji Hou<sup>1</sup>
							  </a>
							</span>,&nbsp;
						  
							<span class="author-block">
							  <a href="https://sites.google.com/view/jialiangwang/home" target="_blank">
								Jialiang Wang<sup>1</sup>
							  </a>
							</span>,&nbsp;
						  
							<span class="author-block">
							  <a href="https://wfchen-umich.github.io/wfchen.github.io/" target="_blank">
								Weifeng Chen<sup>1,*</sup>
							  </a>
							</span>,&nbsp;
						  
							<span class="author-block">
							  <a href="https://zechenghe.github.io/" target="_blank">
								Zecheng He<sup>1,*</sup>
							  </a>
							</span>,&nbsp;
							<br>
						  
							<span class="author-block">
							  <a href="https://xujuefei.com/" target="_blank">
								Felix Juefei-Xu<sup>1</sup>
							  </a>
							</span>,&nbsp;
						  
							<span class="author-block">
							  <a href="https://scholar.google.com/citations?user=wyi0bX0AAAAJ&hl=en" target="_blank">
								Junzhe Sun<sup>1</sup>
							  </a>
							</span>,&nbsp;
						  
							<span class="author-block">
							  <a href="https://scholar.google.com/citations?user=Nb6ggPwAAAAJ&hl=en" target="_blank">
								Zhipeng Fan<sup>1</sup>
							  </a>
							</span>,&nbsp;
						  
							<span class="author-block">
							  <a href="https://www.alithabet.com/" target="_blank">
								Ali Thabet<sup>1</sup>
							  </a>
							</span>,&nbsp;
						  
							<span class="author-block">
							  <a href="https://www.cs.unc.edu/~mbansal/" target="_blank">
								Mohit Bansal<sup>2</sup>
							  </a>
							</span>,&nbsp;
						  
							<span class="author-block">
							  <a href="https://scholar.google.com/citations?user=5aaOtscAAAAJ&hl=en" target="_blank">
								Chu Wang<sup>1</sup>
							  </a>
							</span>
						</div>
						  

						<div class="is-size-5 publication-authors">
							<span class="author-block"><sup>1</sup> Meta Superintelligence Labs</span>,&nbsp;
							<span class="author-block"><sup>2</sup> UNC Chapel Hill</span>,&nbsp;
							<span class="author-block"><sup>3</sup> New York University</span>,&nbsp;
							<span class="author-block"><sup>4</sup> Nanyang Technological University</span>
						</div>
						<div class="is-size-6 publication-authors">
							<span class="author-block"><sup>*</sup> Work done at Meta</span>
						</div>

						<div class="column has-text-centered">
							<div class="publication-links">
								<!-- PDF Link. -->
								<span class="link-block">
									<a href="xxxxx" class="external-link button is-normal is-rounded is-dark">
										<span class="icon">
											<i class="fas fa-file-pdf"></i>
										</span>
										<span>Paper</span>
									</a>
								</span>
								<!-- Code Link. -->
								<span class="link-block">
									<a href="xxxxx" class="external-link button is-normal is-rounded is-dark">
										<span class="icon">
											<i class="fab fa-github"></i>
										</span>
										<span>Code (under review)</span>
									</a>
								</span>
							</div>

						</div>
					</div>
				</div>
			</div>
		</div>
	</section>


	<section class="section">
		<div class="container is-max-desktop">
			<!-- Abstract. -->
			<div class="columns is-centered has-text-centered">
				<div class="column is-four-fifths">
					<h2 class="title is-3">Abstract</h2>
					<div class="content has-text-justified">
						<p>
							Multimodal learning has rapidly advanced visual understanding, largely via multimodal large language models (MLLMs) that use powerful LLMs as cognitive cores. In visual generation, however, these powerful core models are typically reduced to global text encoders for diffusion models, leaving most of their reasoning and planning ability unused. This creates a gap: current multimodal LLMs can parse complex layouts, attributes, and knowledge-intensive scenes, yet struggle to generate images or videos with equally precise and structured control. We propose <b>MetaCanvas</b>, a lightweight framework that lets MLLMs reason and plan directly in spatial and spatiotemporal latent spaces and interface tightly with diffusion generators. We empirically implement MetaCanvas on three different diffusion backbones and evaluate it across six tasks, including text-to-image generation, text/image-to-video generation, image/video editing, and in-context video generation, each requiring precise layouts, robust attribute binding, and reasoning-intensive control. MetaCanvas consistently outperforms global-conditioning baselines, suggesting that treating MLLMs as latent-space planners is a promising direction for narrowing the gap between multimodal understanding and generation.
						</p>
					</div>
				</div>
			</div>
		</div>
	</section>

	<section class="section">
		<div class="container is-max-desktop">
			<div class="columns is-centered has-text-centered">
				<div class="column is-four-fifths">

					<h2 class="title is-3">Method (see more details <a href="#methoddetails">below &darr;</a>)</h2>
					<img src="./static/images/figure1.png" alt="MetaCanvas Main Method Figure" width="99%">
					<br>
					<div class="content has-text-justified">
						<p>
							<b>Figure 1: Overview of the MetaCanvas framework.</b>
							MetaCanvas tokenizes the text and encodes it using the MLLM’s text embedder, while user-provided images and videos are encoded using both the MLLM’s visual encoder and the VAE encoder. 
							The text embeddings produced by the MLLM are passed through a lightweight MLP connector and used as conditioning for the DiT. 
							In addition, we append a set of learnable multidimensional canvas tokens to the MLLM input, which are processed using multimodal RoPE (<a href="https://arxiv.org/abs/2502.13923" target="_blank">Bai et al., 2025b</a>). 
							The resulting canvas embeddings are then fused with the noisy latents through a lightweight transformer-based connector with two blocks. 
							Connector details are illustrated below. 
							<span style="color:green;">Green</span> tokens represent media context tokens, <span style="color:rgb(0, 176, 240);">blue</span> tokens represent text context tokens, and <span style="color:rgb(112, 48, 160);">purple</span> tokens represent the canvas tokens.
						</p>
					</div>

				</div>
			</div>
		</div>
	</section>





	<section class="section">
		<div class="container is-max-desktop" style="max-width: 2500px !important;">
			<div class="columns is-centered has-text-centered">
				<div class="column is-four-fifths">
					<h2 class="title is-3">Generated Video Gallery</h2>
					<p>Here we present examples of in-context video generation, video editing, and text/image-to-video generation.</p>
					<br><br>


					<div class="content is-centered has-text-centered"   style="max-width: 1600px;margin: auto;">
						<h3 class="example-heading">In-Context Video Generation</h3>
						<hr>

						<div style="max-width: 1600px;margin: auto;display: flex;flex-wrap: nowrap;">
							<div class="content example">
								<table>
									<thead>
										<tr style="font-size: 1em;">
											<th>Reference Image 1</th>
											<th></th>
											<th>Reference Image 2 (optional)</th>
											<th></th>
											<th>Input Prompt</th>
											<th></th>
											<th>Generated Video<br></th>
										</tr>
									</thead>
									<tbody>
										
										<!-- Figure25 ref1 -->
										<tr>
											<td>
												<div style="display: flex;width: 150px;margin:auto; ">
													<img width="150px" height="150px"
														src="./static/videos/Figure25/Reference_Images/video1_ref_image.jpg">
												</div>
											</td>

											<td></td>
											
											<td></td>

											<td>
												<img style="position: relative;top:50%;transform: translateY(-50%);"
													width="50px" src="./static/images/plus.png">
											</td>

											<td style="text-align: left;">
												<p style="font-size: 1.1em;">
													Place the anime character with long, flowing light blue hair <span style="color: rgb(112, 48, 160); font-weight: bold;">in a serene garden at sunset, powerfully lifting weights</span>. Sweat glistens on her determined face as she strains against the heavy barbell.
												</p>
											</td>

											<td>
												<img style="position: relative;top:50%;transform: translateY(-50%);"
													width="50px" src="./static/images/arrow_icon.jpg">
											</td>

											<td>
												<div style="display: flex;width: 225px;margin:auto; margin: auto">
													<video style="position: relative;" width="225px" height="125px"
														src="./static/videos/Figure25/MetaCanvas/video1_output.mp4" autoplay muted loop playsinline>
													</video>
												</div>
											</td>
										</tr>


										<!-- Figure25 ref2 -->
										<tr>
											<td>
												<div style="display: flex;width: 150px;margin:auto; ">
													<img width="150px" height="225px"
														src="./static/videos/Figure25/Reference_Images/video2_ref_image.jpg">
												</div>
											</td>

											<td></td>
											
											<td></td>

											<td>
												<img style="position: relative;top:50%;transform: translateY(-50%);"
													width="50px" src="./static/images/plus.png">
											</td>

											<td style="text-align: left;">
												<p style="font-size: 1.1em;">
													Show the man in a suit <span style="color: rgb(112, 48, 160); font-weight: bold;">embracing his partner</span> in a lavender field, both smiling and holding bouquets.
												</p>
											</td>

											<td>
												<img style="position: relative;top:50%;transform: translateY(-50%);"
													width="50px" src="./static/images/arrow_icon.jpg">
											</td>

											<td>
												<div style="display: flex;width: 225px;margin:auto; margin: auto">
													<video style="position: relative;" width="225px" height="125px"
														src="./static/videos/Figure25/MetaCanvas/video2_output.mp4" autoplay muted loop playsinline>
													</video>
												</div>
											</td>
										</tr>



										<!-- Figure25 ref3 -->
										<tr>
											<td>
												<div style="display: flex;width: 200px;margin:auto; ">
													<img width="200px" height="125px"
														src="./static/videos/Figure25/Reference_Images/video3_ref_image.jpg">
												</div>
											</td>

											<td></td>
											
											<td></td>

											<td>
												<img style="position: relative;top:50%;transform: translateY(-50%);"
													width="50px" src="./static/images/plus.png">
											</td>

											<td style="text-align: left;">
												<p style="font-size: 1.1em;">
													Position a slice of tiramisu elegantly on a marble altar in the center of the grand cathedral, <span style="color: rgb(112, 48, 160); font-weight: bold;">surrounded by flickering candlelight</span> that enhances its rich colors.
												</p>
											</td>

											<td>
												<img style="position: relative;top:50%;transform: translateY(-50%);"
													width="50px" src="./static/images/arrow_icon.jpg">
											</td>

											<td>
												<div style="display: flex;width: 225px;margin:auto; margin: auto">
													<video style="position: relative;" width="225px" height="125px"
														src="./static/videos/Figure25/MetaCanvas/video3_output.mp4" autoplay muted loop playsinline>
													</video>
												</div>
											</td>
										</tr>



										<!-- Figure25 ref4 -->
										<tr>
											<td>
												<div style="display: flex;width: 200px;margin:auto; ">
													<img width="200px" height="125px"
														src="./static/videos/Figure25/Reference_Images/video4_ref_image.jpg">
												</div>
											</td>

											<td></td>
											
											<td></td>

											<td>
												<img style="position: relative;top:50%;transform: translateY(-50%);"
													width="50px" src="./static/images/plus.png">
											</td>

											<td style="text-align: left;">
												<p style="font-size: 1.1em;">
													Perch a dark blue starling with white spots <span style="color: rgb(112, 48, 160); font-weight: bold;">on the armrest of a vintage-style armchair</span>, its yellow beak glinting in the warm light filtering through the window.
												</p>
											</td>

											<td>
												<img style="position: relative;top:50%;transform: translateY(-50%);"
													width="50px" src="./static/images/arrow_icon.jpg">
											</td>

											<td>
												<div style="display: flex;width: 225px;margin:auto; margin: auto">
													<video style="position: relative;" width="225px" height="125px"
														src="./static/videos/Figure25/MetaCanvas/video4_output.mp4" autoplay muted loop playsinline>
													</video>
												</div>
											</td>
										</tr>




										<!-- Figure26 ref1 -->
										<tr>
											<td>
												<div style="display: flex;width: 200px;margin:auto; ">
													<img width="200px" height="125px"
														src="./static/videos/Figure26/Reference_Images/video1_ref_image1.jpg">
												</div>
											</td>

											<td>
												<img style="position: relative;top:50%;transform: translateY(-50%);"
													width="50px" src="./static/images/plus.png">
											</td>
											
											<td>
												<div style="display: flex;width: 200px;margin:auto; ">
													<img width="200px" height="125px"
														src="./static/videos/Figure26/Reference_Images/video1_ref_image2.jpg">
												</div>
											</td>

											<td>
												<img style="position: relative;top:50%;transform: translateY(-50%);"
													width="50px" src="./static/images/plus.png">
											</td>

											<td style="text-align: left;">
												<p style="font-size: 1.1em;">
													Set a vibrant peacock perched gracefully <span style="color: rgb(112, 48, 160); font-weight: bold;">on a rustic wooden table</span> in an outdoor café setting, <span style="color: rgb(112, 48, 160); font-weight: bold;">surrounded by potted plants and a charming stone wall</span>, while <span style="color: rgb(112, 48, 160); font-weight: bold;">placing a sleek silver car parked nearby</span>, reflecting the warm sunlight filtering through the glass doors.
												</p>
											</td>

											<td>
												<img style="position: relative;top:50%;transform: translateY(-50%);"
													width="50px" src="./static/images/arrow_icon.jpg">
											</td>

											<td>
												<div style="display: flex;width: 225px;margin:auto; margin: auto">
													<video style="position: relative;" width="225px" height="125px"
														src="./static/videos/Figure26/MetaCanvas/video1_output.mp4" autoplay muted loop playsinline>
													</video>
												</div>
											</td>
										</tr>






										<!-- Figure7  -->
										<tr>
											<td>
												<div style="display: flex;width: 125px;margin:auto; ">
													<img width="125px" height="200px"
														src="./static/videos/Figure8/ref_image_1.jpg">
												</div>
											</td>

											<td>
												<img style="position: relative;top:50%;transform: translateY(-50%);"
													width="50px" src="./static/images/plus.png">
											</td>
											
											<td>
												<div style="display: flex;width: 200px;margin:auto; ">
													<img width="200px" height="125px"
														src="./static/videos/Figure8/ref_image_2.jpg">
												</div>
											</td>

											<td>
												<img style="position: relative;top:50%;transform: translateY(-50%);"
													width="50px" src="./static/images/plus.png">
											</td>

											<td style="text-align: left;">
												<p style="font-size: 1.1em;">
													He gently cradles the bird as it <span style="color: rgb(112, 48, 160); font-weight: bold;">perches delicately on his outstretched fingers</span>, its feathers ruffling slightly in the warm breeze of a tranquil savanna. The golden grass sways softly around them under a vast sky painted with soft pastel hues of dawn, while <span style="color: rgb(112, 48, 160); font-weight: bold;">his focused gaze meets the bird’s bright eyes, creating a quiet moment of connection</span>.
												</p>
											</td>

											<td>
												<img style="position: relative;top:50%;transform: translateY(-50%);"
													width="50px" src="./static/images/arrow_icon.jpg">
											</td>

											<td>
												<div style="display: flex;width: 225px;margin:auto; margin: auto">
													<video style="position: relative;" width="225px" height="125px"
														src="./static/videos/Figure8/metacanvas_video.mp4" autoplay muted loop playsinline>
													</video>
												</div>
											</td>
										</tr>






										<!-- Figure26 ref3 -->
										<tr>
											<td>
												<div style="display: flex;width: 200px;margin:auto; ">
													<img width="200px" height="125px"
														src="./static/videos/Figure26/Reference_Images/video3_ref_image1.jpg">
												</div>
											</td>

											<td>
												<img style="position: relative;top:50%;transform: translateY(-50%);"
													width="50px" src="./static/images/plus.png">
											</td>
											
											<td>
												<div style="display: flex;width: 150px;margin:auto; ">
													<img width="125px" height="200px"
														src="./static/videos/Figure26/Reference_Images/video3_ref_image2.jpg">
												</div>
											</td>

											<td>
												<img style="position: relative;top:50%;transform: translateY(-50%);"
													width="50px" src="./static/images/plus.png">
											</td>

											<td style="text-align: left;">
												<p style="font-size: 1.1em;">
													She reaches out to <span style="color: rgb(112, 48, 160); font-weight: bold;">touch the deer's head</span>, with the deer looking calmly at her in a serene forest setting.
												</p>
											</td>

											<td>
												<img style="position: relative;top:50%;transform: translateY(-50%);"
													width="50px" src="./static/images/arrow_icon.jpg">
											</td>

											<td>
												<div style="display: flex;width: 225px;margin:auto; margin: auto">
													<video style="position: relative;" width="225px" height="125px"
														src="./static/videos/Figure26/MetaCanvas/video3_output.mp4" autoplay muted loop playsinline>
													</video>
												</div>
											</td>
										</tr>






										<!-- Figure26 ref4 -->
										<tr>
											<td>
												<div style="display: flex;width: 150px;margin:auto; ">
													<img width="150px" height="225px"
														src="./static/videos/Figure26/Reference_Images/video4_ref_image1.jpg">
												</div>
											</td>

											<td>
												<img style="position: relative;top:50%;transform: translateY(-50%);"
													width="50px" src="./static/images/plus.png">
											</td>
											
											<td>
												<div style="display: flex;width: 135px;margin:auto; ">
													<img width="135px" height="225px"
														src="./static/videos/Figure26/Reference_Images/video4_ref_image2.jpg">
												</div>
											</td>

											<td>
												<img style="position: relative;top:50%;transform: translateY(-50%);"
													width="50px" src="./static/images/plus.png">
											</td>

											<td style="text-align: left;">
												<p style="font-size: 1.1em;">
													Please make the lady from the first image crouch slightly <span style="color: rgb(112, 48, 160); font-weight: bold;">in a warmly lit living room</span> as she <span style="color: rgb(112, 48, 160); font-weight: bold;">playfully pats</span> the Shiba Inu from photo 2. Her hand is mid-motion, just above the dog’s head. The dog stands on a patterned rug, glancing up with an excited yet puzzled look. A floor lamp casts soft shadows in the cozy, wood- paneled room.
												</p>
											</td>

											<td>
												<img style="position: relative;top:50%;transform: translateY(-50%);"
													width="50px" src="./static/images/arrow_icon.jpg">
											</td>

											<td>
												<div style="display: flex;width: 225px;margin:auto; margin: auto">
													<video style="position: relative;" width="225px" height="125px"
														src="./static/videos/Figure26/MetaCanvas/video4_output.mp4" autoplay muted loop playsinline>
													</video>
												</div>
											</td>
										</tr>




										<!-- Figure27 ref1 -->
										<tr>
											<td>
												<div style="display: flex;width: 200px;margin:auto; ">
													<img width="200px" height="125px"
														src="./static/videos/Figure27/Reference_Images/video1_ref_image1.jpg">
												</div>
											</td>

											<td>
												<img style="position: relative;top:50%;transform: translateY(-50%);"
													width="50px" src="./static/images/plus.png">
											</td>
											
											<td>
												<div style="display: flex;width: 200px;margin:auto; ">
													<img width="200px" height="125px"
														src="./static/videos/Figure27/Reference_Images/video1_ref_image2.jpg">
												</div>
											</td>

											<td>
												<img style="position: relative;top:50%;transform: translateY(-50%);"
													width="50px" src="./static/images/plus.png">
											</td>

											<td style="text-align: left;">
												<p style="font-size: 1.1em;">
													Place the red panda on the edge of the bed, curling up against the decorative pillows as it <span style="color: rgb(112, 48, 160); font-weight: bold;">gazes out the window</span>, soaking in the warm sunlight.
												</p>
											</td>

											<td>
												<img style="position: relative;top:50%;transform: translateY(-50%);"
													width="50px" src="./static/images/arrow_icon.jpg">
											</td>

											<td>
												<div style="display: flex;width: 225px;margin:auto; margin: auto">
													<video style="position: relative;" width="225px" height="150px"
														src="./static/videos/Figure27/MetaCanvas/video1_output.mp4" autoplay muted loop playsinline>
													</video>
												</div>
											</td>
										</tr>



										<!-- Figure27 ref2 -->
										<tr>
											<td>
												<div style="display: flex;width: 200px;margin:auto; ">
													<img width="200px" height="125px"
														src="./static/videos/Figure27/Reference_Images/video2_ref_image1.jpg">
												</div>
											</td>

											<td>
												<img style="position: relative;top:50%;transform: translateY(-50%);"
													width="50px" src="./static/images/plus.png">
											</td>
											
											<td>
												<div style="display: flex;width: 125px;margin:auto; ">
													<img width="125px" height="200px"
														src="./static/videos/Figure27/Reference_Images/video2_ref_image2.jpg">
												</div>
											</td>

											<td>
												<img style="position: relative;top:50%;transform: translateY(-50%);"
													width="50px" src="./static/images/plus.png">
											</td>

											<td style="text-align: left;">
												<p style="font-size: 1.1em;">
													Place the fluffy dog <span style="color: rgb(112, 48, 160); font-weight: bold;">on the wet pavement in front of the modern museum</span>.
												</p>
											</td>

											<td>
												<img style="position: relative;top:50%;transform: translateY(-50%);"
													width="50px" src="./static/images/arrow_icon.jpg">
											</td>

											<td>
												<div style="display: flex;width: 225px;margin:auto; margin: auto">
													<video style="position: relative;" width="225px" height="125px"
														src="./static/videos/Figure27/MetaCanvas/video2_output.mp4" autoplay muted loop playsinline>
													</video>
												</div>
											</td>
										</tr>
								
									</tbody>
								</table>
							</div>
						</div>
						<br><br>
						<br><br>
					</div>
					<br><br>


					<style>
						.video-compare-container {
						  position: relative;
						  width: 640px;
						  height: 360px;
						  margin: 20px auto;
						  user-select: none;
						  background: #000;
						  overflow: hidden;
						}
						.video-compare-img {
						  position: absolute;
						  top: 0; left: 0;
						  width: 100%; height: 100%;
						  object-fit: cover;
						  pointer-events: none;
						}
						.video-compare-edited {
						  clip-path: inset(0 0 0 50%);
						  transition: clip-path 0.05s;
						}
						.video-compare-divider {
						  position: absolute;
						  top: 0; bottom: 0;
						  left: 50%;
						  width: 4px;
						  background: #fff;
						  cursor: ew-resize;
						  z-index: 2;
						  border-radius: 2px;
						  box-shadow: 0 0 4px #0008;
						  transition: background 0.2s;
						  pointer-events: auto;
						}
						.video-compare-divider:hover {
						  background: #0af;
						}
						.video-prompt {
						  margin-top: 4px; /* Reduce this value for less space, e.g., 4px if you want it even tighter */
						  font-size: 1rem;
						  text-align: center;
						}

						/* add this */
						.video-compare-container,
						.video-compare-divider {
							touch-action: none;
						}
					</style>
						



					<div class="content is-centered has-text-centered"   style="max-width: 1600px;margin: auto;">
						<h3 class="example-heading">Video Editing</h3>
						<hr>

						<!-- Figure 7 -->
						<div class="video-editing-row" style="display: flex; gap: 32px; margin-bottom: 32px; justify-content: center; align-items: flex-start;">
							<!-- Video 1 -->
							<div style="flex: 0 0 400px; max-width: 400px;">
							  <div class="video-compare-container" data-index="1" style="width: 400px; height: 225px;">
								<video class="video-compare-img" src="./static/videos/Figure7/video1_input.mp4" autoplay muted loop style="width: 400px; height: 225px; object-fit: cover;"></video>
								<video class="video-compare-img video-compare-edited" src="./static/videos/Figure7/video1_output.mp4" autoplay muted loop style="width: 400px; height: 225px; object-fit: cover;"></video>
								<div class="video-compare-divider"></div>
							  </div>
							  <div class="video-prompt" style="margin-top: 1px;">
								Replace the blue leaf-patterned wall with a <span style="color: rgb(190, 79, 79); font-weight: bold;">soft, textured olive-green wallpaper featuring subtle white floral accents</span>.
							  </div>
							</div>
							<!-- Video 2 -->
							<div style="flex: 0 0 400px; max-width: 400px;">
							  <div class="video-compare-container" data-index="2" style="width: 400px; height: 225px;">
								<video class="video-compare-img" src="./static/videos/Figure7/video2_input.mp4" autoplay muted loop style="width: 400px; height: 225px; object-fit: cover;"></video>
								<video class="video-compare-img video-compare-edited" src="./static/videos/Figure7/video2_output.mp4" autoplay muted loop style="width: 400px; height: 225px; object-fit: cover;"></video>
								<div class="video-compare-divider"></div>
							  </div>
							  <div class="video-prompt" style="margin-top: 1px;">
								Change the projected city background to a <span style="color: rgb(190, 79, 79); font-weight: bold;">rain-soaked, neon-lit street scene in Tokyo with glowing blue signage</span> that matches the room's ambient lighting.
							  </div>
							</div>
							<!-- Video 3 -->
							<div style="flex: 0 0 400px; max-width: 400px;">
							  <div class="video-compare-container" data-index="3" style="width: 400px; height: 225px;">
								<video class="video-compare-img" src="./static/videos/Figure18/video4_input.mp4" autoplay muted loop style="width: 400px; height: 225px; object-fit: cover;"></video>
								<video class="video-compare-img video-compare-edited" src="./static/videos/Figure18/video4_output.mp4" autoplay muted loop style="width: 400px; height: 225px; object-fit: cover;"></video>
								<div class="video-compare-divider"></div>
							  </div>
							  <div class="video-prompt" style="margin-top: 1px;">
								Change the background to a <span style="color: rgb(190, 79, 79); font-weight: bold;">sunlit alpine road with snow-capped mountains and a blue sky</span>.
							  </div>
							</div>
						</div>


						<!-- Figure 20 -->
						<div class="video-editing-row" style="display: flex; gap: 32px; margin-bottom: 32px; justify-content: center; align-items: flex-start;">
							<!-- Video 1 -->
							<div style="flex: 0 0 400px; max-width: 400px;">
							  <div class="video-compare-container" data-index="1" style="width: 400px; height: 225px;">
								<video class="video-compare-img" src="./static/videos/Figure20/video1_input.mp4" autoplay muted loop style="width: 400px; height: 225px; object-fit: cover;"></video>
								<video class="video-compare-img video-compare-edited" src="./static/videos/Figure20/video1_output.mp4" autoplay muted loop style="width: 400px; height: 225px; object-fit: cover;"></video>
								<div class="video-compare-divider"></div>
							  </div>
							  <div class="video-prompt" style="margin-top: 1px;">
								Replace the <span style="color: rgb(190, 79, 79); font-weight: bold;">laptop screen</span> content with a flowing digital watercolor painting in soft teal and gold hues, matching the room's natural lighting.
							  </div>
							</div>
							<!-- Video 2 -->
							<div style="flex: 0 0 400px; max-width: 400px;">
							  <div class="video-compare-container" data-index="2" style="width: 400px; height: 225px;">
								<video class="video-compare-img" src="./static/videos/Figure20/video2_input.mp4" autoplay muted loop style="width: 400px; height: 225px; object-fit: cover;"></video>
								<video class="video-compare-img video-compare-edited" src="./static/videos/Figure20/video2_output.mp4" autoplay muted loop style="width: 400px; height: 225px; object-fit: cover;"></video>
								<div class="video-compare-divider"></div>
							  </div>
							  <div class="video-prompt" style="margin-top: 1px;">
								Add in the background a <span style="color: rgb(190, 79, 79); font-weight: bold;">rustic wooden cabin</span> featuring a glowing window and a snow-laden roof.
							  </div>
							</div>
							<!-- Video 3 -->
							<div style="flex: 0 0 400px; max-width: 400px;">
							  <div class="video-compare-container" data-index="3" style="width: 400px; height: 225px;">
								<video class="video-compare-img" src="./static/videos/Figure20/video3_input.mp4" autoplay muted loop style="width: 400px; height: 225px; object-fit: cover;"></video>
								<video class="video-compare-img video-compare-edited" src="./static/videos/Figure20/video3_output.mp4" autoplay muted loop style="width: 400px; height: 225px; object-fit: cover;"></video>
								<div class="video-compare-divider"></div>
							  </div>
							  <div class="video-prompt" style="margin-top: 1px;">
								Replace the <span style="color: rgb(190, 79, 79); font-weight: bold;">green leaf pattern on the blanket</span> with a delicate pattern of small white daisies on a soft light blue background.
							  </div>
							</div>
						</div>



						<!-- Figure 21 -->
						<div class="video-editing-row" style="display: flex; gap: 32px; margin-bottom: 32px; justify-content: center; align-items: flex-start;">
							<!-- Video 1 -->
							<div style="flex: 0 0 400px; max-width: 400px;">
							  <div class="video-compare-container" data-index="1" style="width: 400px; height: 225px;">
								<video class="video-compare-img" src="./static/videos/Figure21/video1_input.mp4" autoplay muted loop style="width: 400px; height: 225px; object-fit: cover;"></video>
								<video class="video-compare-img video-compare-edited" src="./static/videos/Figure21/video1_output.mp4" autoplay muted loop style="width: 400px; height: 225px; object-fit: cover;"></video>
								<div class="video-compare-divider"></div>
							  </div>
							  <div class="video-prompt" style="margin-top: 1px;">
								Replace the <span style="color: rgb(190, 79, 79); font-weight: bold;">pink coffee cup</span> with a vintage porcelain cup featuring a delicate blue floral pattern, maintaining the same placement and lighting on the green table.
							  </div>
							</div>
							<!-- Video 2 -->
							<div style="flex: 0 0 400px; max-width: 400px;">
							  <div class="video-compare-container" data-index="2" style="width: 400px; height: 225px;">
								<video class="video-compare-img" src="./static/videos/Figure21/video2_input.mp4" autoplay muted loop style="width: 400px; height: 225px; object-fit: cover;"></video>
								<video class="video-compare-img video-compare-edited" src="./static/videos/Figure21/video2_output.mp4" autoplay muted loop style="width: 400px; height: 225px; object-fit: cover;"></video>
								<div class="video-compare-divider"></div>
							  </div>
							  <div class="video-prompt" style="margin-top: 1px;">
								Replace the blurred colorful planets with <span style="color: rgb(190, 79, 79); font-weight: bold;">high-definition, realistic celestial bodies</span> showing visible cloud formations and textured surfaces, matching the boy's space-themed play
							  </div>
							</div>
							<!-- Video 3 -->
							<div style="flex: 0 0 400px; max-width: 400px;">
							  <div class="video-compare-container" data-index="3" style="width: 400px; height: 225px;">
								<video class="video-compare-img" src="./static/videos/Figure21/video3_input.mp4" autoplay muted loop style="width: 400px; height: 225px; object-fit: cover;"></video>
								<video class="video-compare-img video-compare-edited" src="./static/videos/Figure21/video3_output.mp4" autoplay muted loop style="width: 400px; height: 225px; object-fit: cover;"></video>
								<div class="video-compare-divider"></div>
							  </div>
							  <div class="video-prompt" style="margin-top: 1px;">
								Change the copper mug’s surface to a <span style="color: rgb(190, 79, 79); font-weight: bold;">frosty, icy finish with delicate ice crystals forming on its exterior</span>, reflecting the dim snowy light.
							  </div>
							</div>
						</div>



						<!-- Figure 22 -->
						<div class="video-editing-row" style="display: flex; gap: 32px; margin-bottom: 32px; justify-content: center; align-items: flex-start;">
							<!-- Video 1 -->
							<div style="flex: 0 0 400px; max-width: 400px;">
							  <div class="video-compare-container" data-index="1" style="width: 400px; height: 225px;">
								<video class="video-compare-img" src="./static/videos/Figure22/video1_input.mp4" autoplay muted loop style="width: 400px; height: 225px; object-fit: cover;"></video>
								<video class="video-compare-img video-compare-edited" src="./static/videos/Figure22/video1_output.mp4" autoplay muted loop style="width: 400px; height: 225px; object-fit: cover;"></video>
								<div class="video-compare-divider"></div>
							  </div>
							  <div class="video-prompt" style="margin-top: 1px;">
								Replace the guitar's body with a <span style="color: rgb(190, 79, 79); font-weight: bold;">deep, glossy cherry wood finish</span> that mirrors the soft light on the left side of the frame.
							  </div>
							</div>
							<!-- Video 2 -->
							<div style="flex: 0 0 400px; max-width: 400px;">
							  <div class="video-compare-container" data-index="2" style="width: 400px; height: 225px;">
								<video class="video-compare-img" src="./static/videos/Figure22/video2_input.mp4" autoplay muted loop style="width: 400px; height: 225px; object-fit: cover;"></video>
								<video class="video-compare-img video-compare-edited" src="./static/videos/Figure22/video2_output.mp4" autoplay muted loop style="width: 400px; height: 225px; object-fit: cover;"></video>
								<div class="video-compare-divider"></div>
							  </div>
							  <div class="video-prompt" style="margin-top: 1px;">
								Change the background to a <span style="color: rgb(190, 79, 79); font-weight: bold;">smooth, pale green ceramic plate with subtle floral patterns</span>, enhancing the sushi's traditional presentation.
							  </div>
							</div>
							<!-- Video 3 -->
							<div style="flex: 0 0 400px; max-width: 400px;">
							  <div class="video-compare-container" data-index="3" style="width: 400px; height: 225px;">
								<video class="video-compare-img" src="./static/videos/Figure22/video3_input.mp4" autoplay muted loop style="width: 400px; height: 225px; object-fit: cover;"></video>
								<video class="video-compare-img video-compare-edited" src="./static/videos/Figure22/video3_output.mp4" autoplay muted loop style="width: 400px; height: 225px; object-fit: cover;"></video>
								<div class="video-compare-divider"></div>
							  </div>
							  <div class="video-prompt" style="margin-top: 1px;">
								Replace the pineapple-shaped inflatable ring with a <span style="color: rgb(190, 79, 79); font-weight: bold;">smooth, glossy ring that reflects the ocean's blue hues</span>.
							  </div>
							</div>
						</div>




						<!-- Figure 23 -->
						<div class="video-editing-row" style="display: flex; gap: 32px; margin-bottom: 32px; justify-content: center; align-items: flex-start;">
							<!-- Video 1 -->
							<div style="flex: 0 0 400px; max-width: 400px;">
							  <div class="video-compare-container" data-index="1" style="width: 400px; height: 225px;">
								<video class="video-compare-img" src="./static/videos/Figure23/video1_input.mp4" autoplay muted loop style="width: 400px; height: 225px; object-fit: cover;"></video>
								<video class="video-compare-img video-compare-edited" src="./static/videos/Figure23/video1_output.mp4" autoplay muted loop style="width: 400px; height: 225px; object-fit: cover;"></video>
								<div class="video-compare-divider"></div>
							  </div>
							  <div class="video-prompt" style="margin-top: 1px;">
								Change the background to a <span style="color: rgb(190, 79, 79); font-weight: bold;">tranquil, misty alpine meadow</span> with wildflowers and distant snow-capped peaks, maintaining the same warm, natural lighting and camera perspective.
							  </div>
							</div>
							<!-- Video 2 -->
							<div style="flex: 0 0 400px; max-width: 400px;">
							  <div class="video-compare-container" data-index="2" style="width: 400px; height: 225px;">
								<video class="video-compare-img" src="./static/videos/Figure23/video2_input.mp4" autoplay muted loop style="width: 400px; height: 225px; object-fit: cover;"></video>
								<video class="video-compare-img video-compare-edited" src="./static/videos/Figure23/video2_output.mp4" autoplay muted loop style="width: 400px; height: 225px; object-fit: cover;"></video>
								<div class="video-compare-divider"></div>
							  </div>
							  <div class="video-prompt" style="margin-top: 1px;">
								Change the wooden surface to a <span style="color: rgb(190, 79, 79); font-weight: bold;">smooth, light gray stone surface</span> with subtle marbling patterns.
							  </div>
							</div>
							<!-- Video 3 -->
							<div style="flex: 0 0 400px; max-width: 400px;">
							  <div class="video-compare-container" data-index="3" style="width: 400px; height: 225px;">
								<video class="video-compare-img" src="./static/videos/Figure23/video3_input.mp4" autoplay muted loop style="width: 400px; height: 225px; object-fit: cover;"></video>
								<video class="video-compare-img video-compare-edited" src="./static/videos/Figure23/video3_output.mp4" autoplay muted loop style="width: 400px; height: 225px; object-fit: cover;"></video>
								<div class="video-compare-divider"></div>
							  </div>
							  <div class="video-prompt" style="margin-top: 1px;">
								Shift the lighting from cool purple-blue tones to <span style="color: rgb(190, 79, 79); font-weight: bold;">warm golden-hour sunlight</span>, casting honey- gold highlights through the woman's curls while maintaining the slow-motion movement and cinematic depth.
							  </div>
							</div>
						</div>



						<!-- Figure 24 -->
						<div class="video-editing-row" style="display: flex; gap: 32px; margin-bottom: 32px; justify-content: center; align-items: flex-start;">
							<!-- Video 1 -->
							<div style="flex: 0 0 400px; max-width: 400px;">
							  <div class="video-compare-container" data-index="1" style="width: 400px; height: 225px;">
								<video class="video-compare-img" src="./static/videos/Figure24/video1_input.mp4" autoplay muted loop style="width: 400px; height: 225px; object-fit: cover;"></video>
								<video class="video-compare-img video-compare-edited" src="./static/videos/Figure24/video1_output.mp4" autoplay muted loop style="width: 400px; height: 225px; object-fit: cover;"></video>
								<div class="video-compare-divider"></div>
							  </div>
							  <div class="video-prompt" style="margin-top: 1px;">
								Make it <span style="color: rgb(190, 79, 79); font-weight: bold;">Children's Book Illustration</span>.
							  </div>
							</div>
							<!-- Video 2 -->
							<div style="flex: 0 0 400px; max-width: 400px;">
							  <div class="video-compare-container" data-index="2" style="width: 400px; height: 225px;">
								<video class="video-compare-img" src="./static/videos/Figure24/video2_input.mp4" autoplay muted loop style="width: 400px; height: 225px; object-fit: cover;"></video>
								<video class="video-compare-img video-compare-edited" src="./static/videos/Figure24/video2_output.mp4" autoplay muted loop style="width: 400px; height: 225px; object-fit: cover;"></video>
								<div class="video-compare-divider"></div>
							  </div>
							  <div class="video-prompt" style="margin-top: 1px;">
								Convert the video into a <span style="color: rgb(190, 79, 79); font-weight: bold;">pixel art style</span> by reducing the resolution and creating a mosaic effect with square-shaped pixels and simplified colors for a classic pixelated appearance.
							  </div>
							</div>
							<!-- Video 3 -->
							<div style="flex: 0 0 400px; max-width: 400px;">
							  <div class="video-compare-container" data-index="3" style="width: 400px; height: 225px;">
								<video class="video-compare-img" src="./static/videos/Figure24/video3_input.mp4" autoplay muted loop style="width: 400px; height: 225px; object-fit: cover;"></video>
								<video class="video-compare-img video-compare-edited" src="./static/videos/Figure24/video3_output.mp4" autoplay muted loop style="width: 400px; height: 225px; object-fit: cover;"></video>
								<div class="video-compare-divider"></div>
							  </div>
							  <div class="video-prompt" style="margin-top: 1px;">
								Convert the snowy mountain landscape into a <span style="color: rgb(190, 79, 79); font-weight: bold;">watercolor painting</span>.
							  </div>
							</div>
						</div>



					</div>
					
					<script>
						window.addEventListener("DOMContentLoaded", () => {
						  const containers = document.querySelectorAll(".video-compare-container");
					  
						  containers.forEach((container) => {
							const divider = container.querySelector(".video-compare-divider");
							const edited = container.querySelector(".video-compare-edited");
					  
							if (!divider || !edited) return;
					  
							// Ensure divider starts in the middle
							setPosPct(50);
					  
							let dragging = false;
					  
							function setPosFromClientX(clientX) {
							  const rect = container.getBoundingClientRect();
							  const relX = Math.max(0, Math.min(clientX - rect.left, rect.width));
							  const pct = (relX / rect.width) * 100;
							  setPosPct(pct);
							}
					  
							function setPosPct(pct) {
							  divider.style.left = pct + "%";
							  edited.style.clipPath = `inset(0 0 0 ${pct}%)`;
							}
					  
							// Use Pointer Events (works for mouse + touch)
							divider.addEventListener("pointerdown", (e) => {
							  dragging = true;
							  divider.setPointerCapture(e.pointerId);
							  document.body.style.cursor = "ew-resize";
							  setPosFromClientX(e.clientX);
							  e.preventDefault();
							});
					  
							divider.addEventListener("pointermove", (e) => {
							  if (!dragging) return;
							  setPosFromClientX(e.clientX);
							});
					  
							divider.addEventListener("pointerup", () => {
							  dragging = false;
							  document.body.style.cursor = "";
							});
					  
							divider.addEventListener("pointercancel", () => {
							  dragging = false;
							  document.body.style.cursor = "";
							});
					  
							// Optional: let user drag by clicking anywhere on the container
							container.addEventListener("pointerdown", (e) => {
							  // only if not clicking links etc.
							  dragging = true;
							  document.body.style.cursor = "ew-resize";
							  setPosFromClientX(e.clientX);
							});
					  
							window.addEventListener("pointerup", () => {
							  dragging = false;
							  document.body.style.cursor = "";
							});
						  });
						});
					</script>


					<br><br><br>
					<div class="content is-centered has-text-centered"   style="max-width: 1600px;margin: auto;">
						<h3 class="example-heading">Text/Image-to-Video Generation</h3>
						<hr>

						<div style="max-width: 1600px;margin: auto;display: flex;flex-wrap: nowrap;">
							<div class="content example">
								<table>
									<thead>
										<tr style="font-size: 1em;">
											<th>Input Image (Optional)</th>
											<th></th>
											<th>Input Prompt</th>
											<th></th>
											<th>Generated Video<br></th>
										</tr>
									</thead>
									<tbody>
										


										<!-- Figure16 video2 -->
										<tr>
											<td>
											</td>

											<td>
											</td>

											<td style="text-align: left;">
												<p style="font-size: 1.1em;">
													<!-- A person playing guitar. -->
													A person playing a acoustic guitar, strumming gently with expressive fingers, sitting on a wooden stool in a cozy living room. The room is dimly lit with soft candlelight casting warm shadows. Behind them, a vintage wall clock ticks softly. The person wears a t-shirt and jeans, with tousled brown hair framing their face. They play with emotion, occasionally pausing to adjust the strings. The background features old bookshelves filled with various musical instruments and a crackling fireplace. The scene has a nostalgic and intimate atmosphere, capturing the joy and passion of music. Close-up of the guitar and fingers, medium shot of the person and room, low-angle shot of the guitar.
												</p>
											</td>

											<td>
												<img style="position: relative;top:50%;transform: translateY(-50%);"
													width="50px" src="./static/images/arrow_icon.jpg">
											</td>

											<td>
												<div style="display: flex;width: 225px;margin:auto; margin: auto">
													<video style="position: relative;" width="225px" height="125px"
														src="./static/videos/Figure16/video2.mp4" autoplay muted loop playsinline>
													</video>
												</div>
											</td>
										</tr>



										<!-- Figure16 video3 -->
										<tr>
											<td>
											</td>

											<td>
											</td>

											<td style="text-align: left;">
												<p style="font-size: 1.1em;">
													Pixel art style, a cute and happy Corgi playing joyfully in a picturesque park during a beautiful sunset. The Corgi has fluffy white fur, expressive brown eyes, and a wagging tail. It is wearing a small red bowtie around its neck. The park is filled with lush green grass, colorful flowers, and tall trees. The sky is painted with vibrant hues of orange and pink as the sun sets behind a row of buildings. Birds can be seen flying around, adding to the lively atmosphere. The Corgi is running around, chasing butterflies and playing with a small ball. The background includes a mix of pixelated and smooth elements, creating a unique and nostalgic vibe. Pixel art texture, medium shot focusing on the Corgi in action.
												</p>
											</td>

											<td>
												<img style="position: relative;top:50%;transform: translateY(-50%);"
													width="50px" src="./static/images/arrow_icon.jpg">
											</td>

											<td>
												<div style="display: flex;width: 225px;margin:auto; margin: auto">
													<video style="position: relative;" width="225px" height="125px"
														src="./static/videos/Figure16/video3.mp4" autoplay muted loop playsinline>
													</video>
												</div>
											</td>
										</tr>




										<!-- Figure16 video5 -->
										<tr>
											<td>
												<div style="display: flex;width: 200px;margin:auto; ">
													<img width="200px" height="125px"
														src="./static/videos/Figure16/video5.png">
												</div>
											</td>

											<td>
												<img style="position: relative;top:50%;transform: translateY(-50%);"
													width="50px" src="./static/images/plus.png">
											</td>

											<td style="text-align: left;">
												<p style="font-size: 1.1em;">
													A young man is covered in colored powder.
												</p>
											</td>

											<td>
												<img style="position: relative;top:50%;transform: translateY(-50%);"
													width="50px" src="./static/images/arrow_icon.jpg">
											</td>

											<td>
												<div style="display: flex;width: 225px;margin:auto; margin: auto">
													<video style="position: relative;" width="225px" height="125px"
														src="./static/videos/Figure16/video5.mp4" autoplay muted loop playsinline>
													</video>
												</div>
											</td>
										</tr>





										<!-- Figure19 video1 -->
										<tr>
											<td>
												<div style="display: flex;width: 200px;margin:auto; ">
													<img width="200px" height="125px"
														src="./static/videos/Figure19//MetaCanvas/video1.png">
												</div>
											</td>

											<td>
												<img style="position: relative;top:50%;transform: translateY(-50%);"
													width="50px" src="./static/images/plus.png">
											</td>

											<td style="text-align: left;">
												<p style="font-size: 1.1em;">
													Tower bridge in london, camera zooms in.
												</p>
											</td>

											<td>
												<img style="position: relative;top:50%;transform: translateY(-50%);"
													width="50px" src="./static/images/arrow_icon.jpg">
											</td>

											<td>
												<div style="display: flex;width: 225px;margin:auto; margin: auto">
													<video style="position: relative;" width="225px" height="125px"
														src="./static/videos/Figure19//MetaCanvas/video1.mp4" autoplay muted loop playsinline>
													</video>
												</div>
											</td>
										</tr>




								
									</tbody>
								</table>
							</div>
						</div>
					</div>
					<br><br>

				</div>
			</div>
		</div>
	</section>







	<a id="methoddetails"></a>
	<section class="section">
		<div class="container is-max-desktop">
			<div class="columns is-centered has-text-centered">
				<div class="column is-four-fifths">
					<h2 class="title is-3">Method Details</h2>
					<hr>
					<h3 class="title is-4">MetaCanvas connector design</h3>
					
					<img src="./static/images/figure2.png" alt="Teaser Figure" width="50%">

					<br>
					<div class="content" style="text-align: center;">
						<p>
							<b>Figure 2: MetaCanvas connector design details.</b>
						</p>
					</div>
					


					<div class="content has-text-justified">
						<p>
						The canvas connector comprises a vanilla Transformer block and a Diffusion Transformer (DiT) block. The vanilla Transformer block transforms the learnable canvas tokens to align them with the DiT latent space. The second DiT block adopts a ControlNet-style design, where the transformed canvas tokens and the noisy latents are first combined and then passed through a DiT block with Adaptive LayerNorm (<a href="https://arxiv.org/abs/1709.07871" target="_blank">Perez et al., 2018</a>). We adopt Linear-Attn and Mix-FFN design from (<a href="https://arxiv.org/abs/2410.10629" target="_blank">Xie et al., 2024a</a>) to reduce memory usage. The outputs of both blocks are followed by a zero-initialized linear projection layer, ensuring that at the beginning of training, the learnable canvas tokens have no influence on the DiT’s latent inputs.
						</p>
					</div>


					<hr>
					<br><br>
					

					<h3 class="title is-4">MetaCanvas keyframes and reference/condition frames injection strategy for video tasks</h3>

					<img src="./static/images/figure3.png" alt="keyframe injection" width="50%"
						style="background-color: #f0f0f0; text-align: left;">

					<br>
					<div class="content" style="text-align: center;">
						<p>
							<b>Figure 3: MetaCanvas keyframes and reference/condition frames injection strategy for video tasks.</b>
						</p>
					</div>


					<div class="content has-text-justified">
						<p>
							We modify the input layer of Wan2.2-5B (<a href="https://arxiv.org/abs/2503.20314" target="_blank">Wan et al., 2025</a>) to concatenate reference and condition latents with noisy latents along the channel dimension. 
							The resulting tensor is then passed through the patch embedding layer and combined with MetaCanvas keyframes after interpolation. 
							<span style="color: rgb(219, 151, 242); font-weight: bold;">Light purple</span> tokens represent interpolated keyframe canvas. 
							Note that we do not apply MetaCanvas keyframe latents to reference frames for video tasks.
						</p>							
					</div>

					
					<br><br>
					<h2 class="title is-3">Quantitative Results</h2>
					

					<hr>
					<br>
					<h3 class="title is-4">Exploratory Experiments on T2I Generation</h3>

					<br>
					
					<div class="content has-text-justified">
						<p>
						  We aim to validate two questions here:<br>
						  <strong style="color:orange;">Q1:</strong> Does MetaCanvas really help guide the generation process of diffusion models?<br>
						  <strong style="color:orange;">Q2:</strong> What connector design is most effective?
						</p>
					</div>


					<br>
					
					

					<div class="content is-centered has-text-centered">
						<!-- <h5 class="example-heading">Comparison with other design choices</h5> -->
						<!-- Figure 4 with caption -->
						
						<div class="content has-text-justified">
							<p>
								To answer <strong style="color:orange;">Q1</strong>, in 
								<a href="#fig:geneval_curves">Figure 4 (left)</a>, we compare MetaCanvas with 
								(1) the default SANA baseline (T5 text conditioning), 
								(2) an architecture equivalent to MetaQuery 
								<a href="https://arxiv.org/abs/2504.06256" target="_blank">(Pan et al., 2025)</a> 
								that uses 256 learnable 1D query tokens produced by Qwen-2.5-VL while reusing the same text-conditioning interface, 
								and (3) a variant that concatenates T5 text embeddings with the 256 MetaQuery tokens for additional context. 
								As shown, combining text as global guidance with MetaCanvas as a visual prior yields consistent gains and has the fastest GenEval convergence among all variants.
							</p>
						
							<p>
								In <a href="#fig:geneval_curves">Figure 4 (right)</a>, we further evaluate a no-text variant. 
								Even without any text conditioning, adding 2D learnable canvas tokens on top of the noisy latents in DiT provides meaningful structural guidance, 
								demonstrating <em>effective information transfer from the MLLM to the DiT via MetaCanvas</em>.
							</p>
						</div>
						
						<br>
						
						<!-- Figure 4 anchor target -->
						<div id="fig:geneval_curves" class="content" style="text-align: center;">
							<img src="./static/images/figure4.png" 
								 alt="Comparison of training loss and GEdit-Bench scores" 
								 width="60%">
							<br>
							<p>
								<b>Figure 4 Left:</b> Comparison of MetaCanvas with MetaQuery and text conditioning. 
								<b>Right:</b> Comparison of MetaCanvas with and without additional text conditioning.
							</p>
						</div>
						
						<br><br>
						



						<!-- Figure 5 with caption -->						
						<div class="content has-text-justified">
							<p>
								In <a href="#fig:canvas_visualization">Figure 5</a>, we visualize the canvas tokens by training SANA
								(<a href="https://arxiv.org/abs/2410.10629" target="_blank">Xie et al., 2024a</a>) from scratch using only
								canvas tokens from Qwen2.5-VL
								(<a href="https://arxiv.org/abs/2502.13923" target="_blank">Wang et al., 2024a</a>) as the conditioning input,
								with no text signals provided to the DiT.
								Following
								(<a href="https://arxiv.org/abs/2211.12572" target="_blank">Tumanyan et al., 2023</a>),
								we apply PCA to the features produced by the MetaCanvas connector.
								Canvas tokens output from MLLM can serve as reasonable visual planning sketches to effectively guide the final
								image synthesis in the DiT.
							</p>
						</div>

						<!-- Figure 5 anchor target -->
						<div id="fig:canvas_visualization" class="content" style="text-align: center;">
							<img src="./static/images/figure5.png"
								alt="Visualization of canvas features and generated images"
								width="85%">
							<br>
							<p>
								<b>Figure 5: Visualization of canvas features (1st row) and generated images (2nd row) using only canvas
								tokens without extra text conditioning in DiT.</b>
							</p>
						</div>

					
						
					</div>
					<br><br>



					<!-- Table 1 with caption and ID for referencing -->
					<div class="content has-text-justified">
						<p>
							We address <span style="color: orange; font-weight: bold;">Q2</span> with an ablation study on the
							<span class="method">MetaCanvas</span> connector design in
							<a href="#table:geneval_method_ablations">Table&nbsp;1</a>.
							We find that conditioning on the timestep enables dynamic control over the influence of canvas tokens on the noisy latents,
							while the proposed DiT block and accompanying transformer blocks effectively transform and fuse canvas-token information
							with the latents. Moreover, avoiding early projection of canvas tokens into the low-dimensional VAE space yields
							additional gains.
						</p>
					</div>

					<!-- Table 1 -->
					<figure id="table:geneval_method_ablations">
						<img src="./static/images/table3.png"
							alt="Ablation study on MetaCanvas connector design"
							width="45%">
						<figcaption>
							<b>Table 1: Ablation study on MetaCanvas connector design.</b>
						</figcaption>
					</figure>

					


			

					
					<br>
					<hr>
					<br><br>
					<h3 class="title is-4">Results on Image Editing Task</h3>
					
					<div class="content has-text-justified">
						<p>We evaluate the fine-tuned image-editing model FLUX.1-Kontext [Dev] <a href="https://arxiv.org/abs/2506.15742" target="_blank">(Batifol et al., 2025)</a> augmented with MetaCanvas against competing methods on ImgEdit-Bench (see <a href="#table:results_imgedit_short" target="_blank">Table 2</a>) and GEdit-Bench (see <a href="#table:results_gedit_short" target="_blank">Table 3</a>). 
						Equipping FLUX.1-Kontext [Dev] with MetaCanvas yields consistent improvements on both benchmarks.</p>
					</div>
					
					<!-- Table 1 with caption and ID for referencing -->
					<figure id="table:results_imgedit_short">
						<img src="./static/images/table1.png" alt="Quantitative comparison with models on ImgEdit benchmark" width="80%">
						<figcaption>
							<b>Table 2: Quantitative comparison with models on ImgEdit (<a href="https://arxiv.org/abs/2505.20275" target="_blank">Ye et al., 2025</a>) benchmark.</b>
						</figcaption>
					</figure>
					<br>
					
					<!-- Table 2 with caption and ID for referencing -->
					<figure id="table:results_gedit_short">
						<img src="./static/images/table2.png" alt="Quantitative comparison results on GEdit-EN-full benchmark" width="80%">
						<figcaption>
							<b>Table 3: Quantitative comparison results on GEdit-EN-full (<a href="https://arxiv.org/abs/2504.17761" target="_blank">Liu et al., 2025</a>) benchmark.</b>
						</figcaption>
					</figure>
					<br><br>
					
					<div class="content has-text-justified">
						<p><a href="#fig:gedit_curve" target="_blank">Figure 6</a> further contrasts the vanilla model with its MetaCanvas-augmented counterpart under the same training setup, showing steady gains throughout training. 
						Notably, these benefits come from adding only lightweight connector modules, incurring minimal parameter and computational overhead.</p>						
					</div>
					
					<!-- Figure 6 with caption -->
					<figure id="fig:gedit_curve">
						<img src="./static/images/figure6.png" alt="Comparison of training loss and GEdit-Bench scores" width="60%" style="background-color: #f0f0f0; text-align: left;">
						<figcaption>
							<b>Figure 6: Comparison of training loss and GEdit-Bench scores for the baseline method without canvas tokens and MetaCanvas.</b> Both models are fine-tuned on the same training dataset.
						</figcaption>
					</figure>
					
					<br>
					





					<hr>
					<br><br>
					<h3 class="title is-4">Results on Video Generation Task</h3>
					
					<div class="content has-text-justified">
						<p>
							In <a href="#table:results_t2v_i2v">Table&nbsp;4</a>, we compare videos generated by
							<span class="method">MetaCanvas</span> 
							with open-source models, including
							CogVideoX-5B (<a href="https://arxiv.org/abs/2408.06072" target="_blank">Yang et&nbsp;al.,&nbsp;2024</a>),
							HunyuanVideo (<a href="https://arxiv.org/abs/2412.03603" target="_blank">Kong et&nbsp;al.,&nbsp;2024</a>),
							Wan2.1-14B (<a href="https://arxiv.org/abs/2503.20314" target="_blank">Wan et&nbsp;al.,&nbsp;2025</a>),
							and the baseline model Wan2.2-5B
							(<a href="https://arxiv.org/abs/2503.20314" target="_blank">Wan et&nbsp;al.,&nbsp;2025</a>).
							Our method achieves comparable performance while being
							additionally equipped with strong video editing capabilities.
						  </p>						  
					</div>
					
					<!-- Table 1 with caption and ID for referencing -->
					<figure id="table:results_imgedit_short">
						<img src="./static/images/table4.png" alt="Quantitative comparison with models on ImgEdit benchmark" width="50%">
						<figcaption>
							<b>Table 4: Quantitative comparison results on VBench-I2V (<a href="https://arxiv.org/abs/2411.13503" target="_blank">Huang et al., 2024b</a>).</b> Best numbers are bolded, and the second best are underlined.
						</figcaption>
					</figure>
					<br>
					
					


					<hr>
					<br><br>
					<h3 class="title is-4">Results on Video Editing Task</h3>
					
					<div class="content has-text-justified">
						<p>
							We compare <span class="method">MetaCanvas</span> with recent SoTA models,
							including InsViE (<a href="https://arxiv.org/abs/2503.20287" target="_blank">Wu et&nbsp;al.,&nbsp;2025</a>),
							Ditto (<a href="https://arxiv.org/abs/2510.15742" target="_blank">Bai et&nbsp;al.,&nbsp;2025</a>),
							and Lucy-Edit-Dev (<a href="https://huggingface.co/decart-ai/Lucy-Edit-Dev" target="_blank">Decart et&nbsp;al.,&nbsp;2025</a>),
							as well as a control setup of our method that excludes canvas tokens.
							As shown in <a href="#table:results_video_editing">Table&nbsp;5</a>,
							<span class="method">MetaCanvas</span> achieves comparable video quality scores, as measured
							by VBench (<a href="https://arxiv.org/abs/2311.17982" target="_blank">Huang et&nbsp;al.,&nbsp;2023</a>;
							<a href="https://arxiv.org/abs/2411.13503" target="_blank">Huang et&nbsp;al.,&nbsp;2024</a>)
							and GPT-4o (<a href="https://openai.com/index/hello-gpt-4o" target="_blank">OpenAI,&nbsp;2024</a>),
							while outperforming all baselines in editing accuracy (<i>i.e.</i>, semantics) by a large margin.
							In addition, we conduct human evaluations comparing Lucy-Edit-Dev&nbsp;v1.1, Ditto,
							and <span class="method">MetaCanvas</span>, and report the win rates for editing accuracy,
							spatio-temporal consistency, and overall user preference.
							<span class="method">MetaCanvas</span> achieves the highest preference rate across all
							evaluation dimensions.
							Furthermore, the controlled variant without canvas tokens attains competitive or better
							performance relative to other baselines, demonstrating the effectiveness of replacing
							the text encoder with a MLLM-based multimodal condition encoder.
						  </p>						  
					</div>
					  
					
					<!-- Table 5 with caption and ID for referencing -->
					<figure id="table:results_video_editing">
						<img src="./static/images/table5.png" alt="Quantitative comparison results on GEdit-EN-full benchmark" width="85%">
						<figcaption>
							<b>Table 5: Quantitative comparison on video editing task.</b> Best numbers are bolded, and the second best are underlined.
						</figcaption>
					</figure>
					<br>
					

					





					<hr>
					<br><br>
					<h3 class="title is-4">Results on In-Context Video Generation Task</h3>
					
					<div class="content has-text-justified">
						<p>
							In <a href="#table:results_omnicontext_video">Table&nbsp;6</a>, we compare
							<span class="method">MetaCanvas</span> with Wan-VACE
							(<a href="https://arxiv.org/abs/2503.07598" target="_blank">Jiang et&nbsp;al.,&nbsp;2025</a>)
							1.3B/14B on video generation from reference images.
							<span class="method">MetaCanvas</span> achieves competitive performance with these baselines,
							particularly on human-object interaction tasks (<i>i.e.</i>, character&nbsp;+&nbsp;object
							under multiple ID categories).
						  </p>									  
					</div>
					
					<!-- Table 1 with caption and ID for referencing -->
					<figure id="table:results_omnicontext_video">
						<img src="./static/images/table15.png" alt="Quantitative comparison with models on ImgEdit benchmark" width="85%">
						<figcaption>
							<b>Table 6 Quantitative comparison results on our OmniContext-Video benchmark for in-context video generation from reference images.
						</figcaption>
					</figure>
					<!-- <br> -->
					<!-- <hr> -->
					
				</div>
			</div>
		</div>
	</section>







<!-- 

	<section class="section" id="Limitations and Future Works">
		<div class="container is-max-desktop content">
			<h2 class="title">Limitations and Future Works</h2>
			<p>
			In this work, we primarily focus on investigating the effectiveness of information transfer between MLLMs and diffusion Transformers via MetaCanvas. 
			Our approach follows prior work that bridges MLLMs with diffusion models through lightweight connector interfaces. 
			One potential limitation of the current setup is that visual information (e.g., images and videos) is provided to both the MLLM and the diffusion models, following previous works
			(<a href="https://arxiv.org/abs/2510.08377" target="_blank">Wei et al., 2025</a>,
			<a href="https://arxiv.org/abs/2508.02324" target="_blank">Wu et al., 2025a</a>,
			<a href="https://arxiv.org/abs/2506.03147" target="_blank">Lin et al., 2025</a>,
			<a href="https://arxiv.org/abs/2506.18871" target="_blank">Wu et al., 2025b</a>,
			<a href="https://arxiv.org/abs/2504.17761" target="_blank">Liu et al., 2025</a>)
			to maximize performance. 
			It would be interesting to explore whether a more elegant framework could be designed that passes all visual information solely to the MLLM, allowing DiT to directly render images and videos without repeated conditioning on visual inputs.
			</p>
			
			<p>
			Additionally, we evaluated the effectiveness of MetaCanvas across diverse tasks using text, image, video, or combinations thereof as inputs. 
			However, we note that the quality of our curated training data is not optimal, and the scale of the data is limited for some of the tasks. 
			For instance, we observed that the success rate for in-context video generation from three or more reference images is not high. 
			Expanding the task-specific dataset could further improve performance.
			</p>
		</div>
	</section> -->

	<section class="section" id="BibTeX">
		<div class="container is-max-desktop content">
			<h2 class="title">BibTeX</h2>
			<pre><code>@article{Lin2025MetaCanvas,
	author = {Han Lin,  Xichen Pan,  Ziqi Huang,  Ji Hou,  Jialiang Wang,  Weifeng Chen,  Zecheng He,  Felix Juefei-Xu,  Junzhe Sun,  Zhipeng Fan,  Ali Thabet,  Mohit Bansal,  Chu Wang},
	title  = {Exploring MLLM-Diffusion Information Transfer with MetaCanvas},
	year   = {2025},
}</code></pre>
		</div>
	</section>


	<footer class="footer">
		<div class="container">
			<div class="columns is-centered">
				<div class="column is-8">
					<div class="content">
						The webpage was adapted from <a href="https://github.com/nerfies/nerfies.github.io">nerfies</a>.
					</div>
				</div>
			</div>
		</div>
	</footer>



<!-- Add the draggable divider script here -->
<script>
	document.querySelectorAll('.video-compare-container').forEach(container => {
	  const inputVideo = container.querySelector('.video-compare-input');
	  const editedVideo = container.querySelector('.video-compare-edited');
	
	  function syncPlay() {
		if (inputVideo.paused) editedVideo.pause();
		else {
		  editedVideo.currentTime = inputVideo.currentTime;
		  editedVideo.play();
		}
	  }
	
	  function syncPause() {
		editedVideo.pause();
	  }
	
	  function syncSeek() {
		editedVideo.currentTime = inputVideo.currentTime;
	  }
	
	  function syncLoop() {
		inputVideo.currentTime = 0;
		editedVideo.currentTime = 0;
		inputVideo.play();
		editedVideo.play();
	  }
	
	  inputVideo.addEventListener('play', syncPlay);
	  inputVideo.addEventListener('pause', syncPause);
	  inputVideo.addEventListener('seeked', syncSeek);
	  inputVideo.addEventListener('timeupdate', () => {
		// Keep videos in sync (small drift correction)
		if (Math.abs(inputVideo.currentTime - editedVideo.currentTime) > 0.05) {
		  editedVideo.currentTime = inputVideo.currentTime;
		}
	  });
	  inputVideo.addEventListener('ended', syncLoop);
	
	  // Optionally, start both videos together when loaded
	  inputVideo.addEventListener('loadeddata', () => {
		editedVideo.currentTime = inputVideo.currentTime;
	  });
	  editedVideo.addEventListener('loadeddata', () => {
		inputVideo.currentTime = editedVideo.currentTime;
	  });
	});
</script>
<!-- Existing scripts and styles -->
<style>
	code {
		display: block;
	}
</style>
<script>
		var code = document.querySelector('pre code');
		code.innerHTML = code.textContent.replace(/(\w)/, '<span>$1');
		var left = code.querySelector('span').getClientRects()[0].left;
		code.style.marginLeft = (-left + code.getClientRects()[0].left) + 'px';  
</script>
	


</body>
<style>
	code {
		display: block;
	}
</style>
<script>
	var code = document.querySelector('pre code');
	code.innerHTML = code.textContent.replace(/(\w)/, '<span>$1');
	var left = code.querySelector('span').getClientRects()[0].left;
	code.style.marginLeft = (-left + code.getClientRects()[0].left) + 'px';  
</script>

</html>